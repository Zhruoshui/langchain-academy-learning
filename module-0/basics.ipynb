{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# LangChain å­¦é™¢\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° LangChain å­¦é™¢ï¼\n",
    "\n",
    "## èƒŒæ™¯\n",
    "\n",
    "åœ¨ LangChainï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©æ„å»º LLM åº”ç”¨å˜å¾—ç®€å•ã€‚å…¶ä¸­ä¸€ç§å¯ä»¥æ„å»ºçš„ LLM åº”ç”¨æ˜¯ä»£ç†ï¼ˆagentï¼‰ã€‚ä»£ç†çš„å¼€å‘å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥è‡ªåŠ¨æ‰§è¡Œä¸€ç³»åˆ—æ­¤å‰æ— æ³•å®Œæˆçš„ä»»åŠ¡ã€‚\n",
    "\n",
    "ä½†åœ¨å®é™…ä¸­ï¼Œæ„å»ºèƒ½å¤Ÿå¯é æ‰§è¡Œè¿™äº›ä»»åŠ¡çš„ç³»ç»Ÿéå¸¸å›°éš¾ã€‚åœ¨æˆ‘ä»¬ä¸ç”¨æˆ·å°†ä»£ç†æŠ•å…¥ç”Ÿäº§ç¯å¢ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°é€šå¸¸éœ€è¦æ›´å¤šçš„æ§åˆ¶ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½éœ€è¦ä»£ç†å§‹ç»ˆå…ˆè°ƒç”¨æŸä¸ªç‰¹å®šå·¥å…·ï¼Œæˆ–æ ¹æ®çŠ¶æ€ä½¿ç”¨ä¸åŒçš„æç¤ºï¼ˆpromptï¼‰ã€‚\n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº† [LangGraph](https://docs.langchain.com/oss/python/langgraph/overview) â€”â€” ä¸€ä¸ªç”¨äºæ„å»ºä»£ç†å’Œå¤šä»£ç†åº”ç”¨çš„æ¡†æ¶ã€‚LangGraph ä¸ LangChain åŒ…æ˜¯åˆ†ç¦»çš„ï¼Œå…¶æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯å¸®åŠ©å¼€å‘è€…åœ¨ä»£ç†å·¥ä½œæµä¸­å¼•å…¥æ›´ç²¾ç¡®çš„æ§åˆ¶ï¼Œä»¥é€‚åº”çœŸå®ä¸–ç•Œç³»ç»Ÿçš„å¤æ‚æ€§ã€‚\n",
    "\n",
    "## è¯¾ç¨‹ç»“æ„\n",
    "\n",
    "æœ¬è¯¾ç¨‹ç”±è‹¥å¹²æ¨¡å—ç»„æˆï¼Œæ¯ä¸ªæ¨¡å—èšç„¦ LangGraph çš„æŸä¸ªä¸»é¢˜ã€‚ä½ ä¼šçœ‹åˆ°æ¯ä¸ªæ¨¡å—å¯¹åº”çš„æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—ç¬”è®°æœ¬ï¼ˆnotebookï¼‰ã€‚æ¯ä¸ªç¬”è®°æœ¬é€šå¸¸é…æœ‰è®²è§£è§†é¢‘ä»¥è¾…åŠ©ç†è§£ï¼Œä½†ç¬”è®°æœ¬æœ¬èº«ä¹Ÿèƒ½ç‹¬ç«‹é˜…è¯»ï¼ŒåŒ…å«äº†å¿…è¦çš„è¯´æ˜ã€‚æ¯ä¸ªæ¨¡å—æ–‡ä»¶å¤¹è¿˜åŒ…å«ä¸€ä¸ª `studio` æ–‡ä»¶å¤¹ï¼Œé‡Œé¢æœ‰å¯ä»¥åŠ è½½åˆ° [LangSmith Studio](https://docs.langchain.com/langsmith/quick-start-studio)ï¼ˆæˆ‘ä»¬ç”¨äºæ„å»º LangGraph åº”ç”¨çš„ IDEï¼‰ä¸­çš„å›¾ï¼ˆgraphsï¼‰ã€‚\n",
    "\n",
    "## ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§ `README` ä¸­çš„è¯´æ˜åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–ã€‚\n",
    "\n",
    "## èŠå¤©æ¨¡å‹\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨èŠå¤©æ¨¡å‹ï¼ˆChat Modelsï¼‰ï¼Œå®ƒä»¬ä»¥ä¸€ç³»åˆ—æ¶ˆæ¯ä½œä¸ºè¾“å…¥å¹¶è¿”å›æ¶ˆæ¯ä½œä¸ºè¾“å‡ºã€‚LangChain é€šè¿‡[ç¬¬ä¸‰æ–¹é›†æˆ](https://docs.langchain.com/oss/python/integrations/chat)æ”¯æŒå¤šç§æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¾ç¨‹å°†ä½¿ç”¨ [ChatOpenAI](https://docs.langchain.com/oss/python/integrations/chat/openai)ï¼Œå› ä¸ºå®ƒæ—¢æµè¡Œåˆæ€§èƒ½è‰¯å¥½ã€‚è¯·ç¡®ä¿å·²è®¾ç½® `OPENAI_API_KEY` ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†æ£€æŸ¥ `OPENAI_API_KEY` æ˜¯å¦è®¾ç½®ï¼Œå¦‚æœªè®¾ç½®ä¼šæç¤ºä½ è¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# è®¾ç½®ç¬¬ä¸‰æ–¹ API Key\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# è®¾ç½®ç¬¬ä¸‰æ–¹ API Base URLï¼ˆå¿…éœ€ï¼‰\n",
    "# ä¾‹å¦‚: \n",
    "# DeepSeek: https://api.deepseek.com/v1\n",
    "# æ™ºè°± AI: https://open.bigmodel.cn/api/paas/v4\n",
    "# æœˆä¹‹æš—é¢ (Kimi): https://api.moonshot.cn/v1\n",
    "# é˜¿é‡Œäº‘ç™¾ç‚¼: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
    "_set_env(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[è¿™é‡Œ](https://docs.langchain.com/oss/python/langchain/models) æœ‰ä¸€ä»½å…³äºèŠå¤©æ¨¡å‹å¯ç”¨åŠŸèƒ½çš„å®ç”¨æŒ‡å—ï¼Œä¸‹é¢æˆ‘ä»¬ä¼šå±•ç¤ºä¸€äº›è¦ç‚¹ã€‚å¦‚æœä½ å·²ç»æŒ‰ç…§ README ä¸­çš„è¯´æ˜è¿è¡Œäº† `pip install -r requirements.txt`ï¼Œé‚£ä¹ˆä½ å·²ç»å®‰è£…äº† `langchain-openai` åŒ…ã€‚ä½¿ç”¨è¯¥åŒ…æˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ– `ChatOpenAI` æ¨¡å‹å¯¹è±¡ã€‚ä½ å¯ä»¥åœ¨ [è¿™é‡Œ](https://openai.com/api/pricing/) æŸ¥çœ‹å„ç§æ¨¡å‹çš„å®šä»·ã€‚ç¬”è®°æœ¬ä¸­é»˜è®¤ä¼šä½¿ç”¨ `gpt-4o`ï¼Œå› ä¸ºå®ƒåœ¨è´¨é‡ã€ä»·æ ¼å’Œé€Ÿåº¦ä¹‹é—´æœ‰è‰¯å¥½å¹³è¡¡ï¼Œä½†ä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä»·æ ¼æ›´ä½çš„ `gpt-3.5` ç³»åˆ—æˆ–å…¶ä»–æ›´æ–°çš„æ¨¡å‹ã€‚\n",
    "\n",
    "æœ‰[ä¸€äº›å¸¸è§å‚æ•°](https://docs.langchain.com/oss/python/langchain/models#parameters) å¯ä»¥ç”¨äºèŠå¤©æ¨¡å‹ã€‚å…¶ä¸­ä¸¤ä¸ªæœ€å¸¸ç”¨çš„æ˜¯ï¼š\n",
    "\n",
    "* `model`ï¼šæ¨¡å‹åç§°\n",
    "* `temperature`ï¼šé‡‡æ ·æ¸©åº¦\n",
    "\n",
    "`temperature` æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§æˆ–åˆ›é€ æ€§ï¼Œæ¸©åº¦ä½ï¼ˆæ¥è¿‘ 0ï¼‰æ—¶è¾“å‡ºæ›´ç¡®å®šã€æ›´èšç„¦ï¼Œé€‚ç”¨äºéœ€è¦å‡†ç¡®æˆ–åŸºäºäº‹å®çš„ä»»åŠ¡ï¼›æ¸©åº¦é«˜ï¼ˆæ¥è¿‘ 1ï¼‰æ—¶æ›´é€‚åˆåˆ›æ„ç±»ä»»åŠ¡æˆ–ç”Ÿæˆå¤šæ ·åŒ–å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19a54d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®\n",
    "# OPENAI_API_KEY å’Œ OPENAI_API_BASE ä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–\n",
    "dsv3_2_chat = ChatOpenAI(model=\"deepseek-ai/DeepSeek-V3.2-Exp\", temperature=0)\n",
    "MiniMax_M2_chat = ChatOpenAI(model=\"MiniMaxAI/MiniMax-M2\", temperature=0)\n",
    "\n",
    "# æ³¨æ„ï¼šè¯·æ ¹æ®ä½ ä½¿ç”¨çš„ç¬¬ä¸‰æ–¹æœåŠ¡ä¿®æ”¹ model å‚æ•°\n",
    "# ä¾‹å¦‚ï¼š\n",
    "# DeepSeek: model=\"deepseek-chat\"\n",
    "# æ™ºè°± AI: model=\"glm-4\"\n",
    "# æœˆä¹‹æš—é¢: model=\"moonshot-v1-8k\"\n",
    "# é˜¿é‡Œé€šä¹‰åƒé—®: model=\"qwen-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "LangChain ä¸­çš„èŠå¤©æ¨¡å‹æœ‰è®¸å¤š[é»˜è®¤æ–¹æ³•](https://reference.langchain.com/python/langchain_core/runnables)ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ï¼š\n",
    "\n",
    "* [stream](https://docs.langchain.com/oss/python/langchain/models#stream)ï¼šæµå¼è¿”å›å“åº”ç‰‡æ®µ\n",
    "* [invoke](https://docs.langchain.com/oss/python/langchain/models#invoke)ï¼šå¯¹è¾“å…¥è°ƒç”¨æ¨¡å‹\n",
    "\n",
    "å¦‚å‰æ‰€è¿°ï¼ŒèŠå¤©æ¨¡å‹ä»¥[æ¶ˆæ¯ï¼ˆmessagesï¼‰](https://docs.langchain.com/oss/python/langchain/messages)ä½œä¸ºè¾“å…¥ã€‚æ¶ˆæ¯æœ‰ä¸€ä¸ªè§’è‰²ï¼ˆæè¿°è°åœ¨è¯´è¯ï¼‰å’Œå†…å®¹å±æ€§ï¼ˆcontentï¼‰ã€‚æˆ‘ä»¬ä¹‹åä¼šæ›´è¯¦ç»†è®¨è®ºï¼Œè¿™é‡Œå…ˆå±•ç¤ºåŸºæœ¬ç”¨æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1280e1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello world! ğŸ‘‹ \\n\\nIt's great to see you! How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 8, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'deepseek-ai/DeepSeek-V3.2-Exp', 'system_fingerprint': '', 'id': '019a9c87aabab3722475eb9fd4fc8b77', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ccfb2fc3-9d63-4424-a159-8400f99abd8f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 20, 'total_tokens': 28, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "dsv3_2_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª `AIMessage` å“åº”ã€‚å¦è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥ç”¨å­—ç¬¦ä¸²è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚å½“ä»¥å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥æ—¶ï¼Œè¯¥å­—ç¬¦ä¸²ä¼šè¢«è½¬æ¢ä¸ºä¸€ä¸ª `HumanMessage`ï¼Œç„¶åä¼ é€’ç»™åº•å±‚æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CSWGCXlVYTEWoHAFm3GXIIgUO1gCb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--43b070a6-7676-4aa1-984c-c0cd43d45c1e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsv3_2_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CSWGDY5KePqihRcWDX3IGEZfSoyld', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f7963c03-f8b2-4eba-bc7f-4d58520fa661-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MiniMax_M2_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "ä¸åŒèŠå¤©æ¨¡å‹ä¹‹é—´çš„æ¥å£æ˜¯ä¸€è‡´çš„ï¼Œæ¨¡å‹é€šå¸¸åœ¨æ¯ä¸ªç¬”è®°æœ¬å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œå¦‚æœä½ æ›´åå¥½å…¶ä»–æä¾›å•†ï¼Œå¯ä»¥åœ¨ä¸æ›´æ”¹ä¸‹æ¸¸ä»£ç çš„æƒ…å†µä¸‹è½»æ¾åˆ‡æ¢æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## æœç´¢å·¥å…·\n",
    "\n",
    "åœ¨ README ä¸­ä½ è¿˜ä¼šçœ‹åˆ° [Tavily](https://tavily.com/)ï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸º LLM å’Œ RAG ä¼˜åŒ–çš„æœç´¢å¼•æ“ï¼Œæ—¨åœ¨æä¾›é«˜æ•ˆã€å¿«é€Ÿä¸”æŒä¹…çš„æœç´¢ç»“æœã€‚å¦‚å‰æ‰€è¿°ï¼Œæ³¨å†Œå¾ˆå®¹æ˜“ä¸”æä¾›äº†å®½æ¾çš„å…è´¹é¢åº¦ã€‚ç¬¬ 4 æ¨¡å—ä¸­çš„æŸäº›è¯¾ç¨‹å°†é»˜è®¤ä½¿ç”¨ Tavilyï¼Œä½†å½“ç„¶å¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨ä»£ç ä¸­æ›¿æ¢ä¸ºå…¶ä»–æœç´¢å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch  # updated at 1.0\n",
    "\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "data = tavily_search.invoke({\"query\": \"What is LangGraph?\"})\n",
    "type(data)\n",
    "search_docs = data.get(\"results\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "  'score': 0.9999573,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'content': 'LangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. By treating workflows as interconnected nodes and edges, LangGraph offers a scalable, transparent and developer-friendly way to design advanced AI systems ranging from simple chatbots to multi-agent system. * ****Enhanced decision-making:**** Models relationships between nodes, enabling AI agents to learn from past actions and feedback. * ****langgraph:**** Framework for building graph-based AI workflows. * Build the workflow graph using LangGraph, adding nodes for classification and response, connecting them with edges and compiling the app. * Send each input through the workflow graph and returns the botâ€™s response, either a greeting or an AI-powered answer.',\n",
       "  'score': 0.99990463,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://k21academy.com/ai-ml/langgraph-overview/',\n",
       "  'title': \"What is LangGraph: Beginner's Guide | K21Academy\",\n",
       "  'content': 'Consider it as a â€œmapâ€ of your AI logic, with the edges defining the data flow between the nodes, each of which represents a distinct phase or agent (such as creating content, retrieving data, or summarising text). So, if LangChain is the engine, LangGraph is the GPS that makes sure your AI agents follow the right route. * created to control states and workflows across many AI agents or tools. LangGraph is part of a broader shift toward Agentic AI â€” systems where multiple LLM-based agents interact autonomously. In conclusion, LangGraph represents a significant breakthrough in the creation of AI agents. LangGraph powers real-world projects such as AI-powered chatbots for customer support, research systems that process complex data, and trading algorithms that analyze market trends',\n",
       "  'score': 0.99984396,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7545f4-aeb7-4b03-91f5-df3e021fe960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
