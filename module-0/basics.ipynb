{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# LangChain å­¦é™¢\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° LangChain å­¦é™¢ï¼\n",
    "\n",
    "## èƒŒæ™¯\n",
    "\n",
    "åœ¨ LangChainï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©æ„å»º LLM åº”ç”¨å˜å¾—ç®€å•ã€‚å…¶ä¸­ä¸€ç§å¯ä»¥æ„å»ºçš„ LLM åº”ç”¨æ˜¯ä»£ç†ï¼ˆagentï¼‰ã€‚ä»£ç†çš„å¼€å‘å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥è‡ªåŠ¨æ‰§è¡Œä¸€ç³»åˆ—æ­¤å‰æ— æ³•å®Œæˆçš„ä»»åŠ¡ã€‚\n",
    "\n",
    "ä½†åœ¨å®é™…ä¸­ï¼Œæ„å»ºèƒ½å¤Ÿå¯é æ‰§è¡Œè¿™äº›ä»»åŠ¡çš„ç³»ç»Ÿéå¸¸å›°éš¾ã€‚åœ¨æˆ‘ä»¬ä¸ç”¨æˆ·å°†ä»£ç†æŠ•å…¥ç”Ÿäº§ç¯å¢ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°é€šå¸¸éœ€è¦æ›´å¤šçš„æ§åˆ¶ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½éœ€è¦ä»£ç†å§‹ç»ˆå…ˆè°ƒç”¨æŸä¸ªç‰¹å®šå·¥å…·ï¼Œæˆ–æ ¹æ®çŠ¶æ€ä½¿ç”¨ä¸åŒçš„æç¤ºï¼ˆpromptï¼‰ã€‚\n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº† [LangGraph](https://docs.langchain.com/oss/python/langgraph/overview) â€”â€” ä¸€ä¸ªç”¨äºæ„å»ºä»£ç†å’Œå¤šä»£ç†åº”ç”¨çš„æ¡†æ¶ã€‚LangGraph ä¸ LangChain åŒ…æ˜¯åˆ†ç¦»çš„ï¼Œå…¶æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯å¸®åŠ©å¼€å‘è€…åœ¨ä»£ç†å·¥ä½œæµä¸­å¼•å…¥æ›´ç²¾ç¡®çš„æ§åˆ¶ï¼Œä»¥é€‚åº”çœŸå®ä¸–ç•Œç³»ç»Ÿçš„å¤æ‚æ€§ã€‚\n",
    "\n",
    "## è¯¾ç¨‹ç»“æ„\n",
    "\n",
    "æœ¬è¯¾ç¨‹ç”±è‹¥å¹²æ¨¡å—ç»„æˆï¼Œæ¯ä¸ªæ¨¡å—èšç„¦ LangGraph çš„æŸä¸ªä¸»é¢˜ã€‚ä½ ä¼šçœ‹åˆ°æ¯ä¸ªæ¨¡å—å¯¹åº”çš„æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—ç¬”è®°æœ¬ï¼ˆnotebookï¼‰ã€‚æ¯ä¸ªç¬”è®°æœ¬é€šå¸¸é…æœ‰è®²è§£è§†é¢‘ä»¥è¾…åŠ©ç†è§£ï¼Œä½†ç¬”è®°æœ¬æœ¬èº«ä¹Ÿèƒ½ç‹¬ç«‹é˜…è¯»ï¼ŒåŒ…å«äº†å¿…è¦çš„è¯´æ˜ã€‚æ¯ä¸ªæ¨¡å—æ–‡ä»¶å¤¹è¿˜åŒ…å«ä¸€ä¸ª `studio` æ–‡ä»¶å¤¹ï¼Œé‡Œé¢æœ‰å¯ä»¥åŠ è½½åˆ° [LangSmith Studio](https://docs.langchain.com/langsmith/quick-start-studio)ï¼ˆæˆ‘ä»¬ç”¨äºæ„å»º LangGraph åº”ç”¨çš„ IDEï¼‰ä¸­çš„å›¾ï¼ˆgraphsï¼‰ã€‚\n",
    "\n",
    "## ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§ `README` ä¸­çš„è¯´æ˜åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–ã€‚\n",
    "\n",
    "## èŠå¤©æ¨¡å‹\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨èŠå¤©æ¨¡å‹ï¼ˆChat Modelsï¼‰ï¼Œå®ƒä»¬ä»¥ä¸€ç³»åˆ—æ¶ˆæ¯ä½œä¸ºè¾“å…¥å¹¶è¿”å›æ¶ˆæ¯ä½œä¸ºè¾“å‡ºã€‚LangChain é€šè¿‡[ç¬¬ä¸‰æ–¹é›†æˆ](https://docs.langchain.com/oss/python/integrations/chat)æ”¯æŒå¤šç§æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¾ç¨‹å°†ä½¿ç”¨ [ChatOpenAI](https://docs.langchain.com/oss/python/integrations/chat/openai)ï¼Œå› ä¸ºå®ƒæ—¢æµè¡Œåˆæ€§èƒ½è‰¯å¥½ã€‚è¯·ç¡®ä¿å·²è®¾ç½® `OPENAI_API_KEY` ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†æ£€æŸ¥ `OPENAI_API_KEY` æ˜¯å¦è®¾ç½®ï¼Œå¦‚æœªè®¾ç½®ä¼šæç¤ºä½ è¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from rich import print as rprint\n",
    "\n",
    "# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ï¼‰\n",
    "project_root = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "env_path = project_root / '.env'\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "required_vars = ['OPENAI_API_KEY', 'OPENAI_API_BASE', 'MODEL_NAME']\n",
    "missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    rprint(f\"[red]è­¦å‘Š: ä»¥ä¸‹ç¯å¢ƒå˜é‡æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®: {', '.join(missing_vars)}[/red]\")\n",
    "else:\n",
    "    rprint(f\"[green]âœ“ ç¯å¢ƒå˜é‡å·²ä» {env_path} æˆåŠŸåŠ è½½[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[è¿™é‡Œ](https://docs.langchain.com/oss/python/langchain/models) æœ‰ä¸€ä»½å…³äºèŠå¤©æ¨¡å‹å¯ç”¨åŠŸèƒ½çš„å®ç”¨æŒ‡å—ï¼Œä¸‹é¢æˆ‘ä»¬ä¼šå±•ç¤ºä¸€äº›è¦ç‚¹ã€‚å¦‚æœä½ å·²ç»æŒ‰ç…§ README ä¸­çš„è¯´æ˜è¿è¡Œäº† `pip install -r requirements.txt`ï¼Œé‚£ä¹ˆä½ å·²ç»å®‰è£…äº† `langchain-openai` åŒ…ã€‚ä½¿ç”¨è¯¥åŒ…æˆ‘ä»¬å¯ä»¥å®ä¾‹åŒ– `ChatOpenAI` æ¨¡å‹å¯¹è±¡ã€‚ä½ å¯ä»¥åœ¨ [è¿™é‡Œ](https://openai.com/api/pricing/) æŸ¥çœ‹å„ç§æ¨¡å‹çš„å®šä»·ã€‚ç¬”è®°æœ¬ä¸­é»˜è®¤ä¼šä½¿ç”¨ `gpt-4o`ï¼Œå› ä¸ºå®ƒåœ¨è´¨é‡ã€ä»·æ ¼å’Œé€Ÿåº¦ä¹‹é—´æœ‰è‰¯å¥½å¹³è¡¡ï¼Œä½†ä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä»·æ ¼æ›´ä½çš„ `gpt-3.5` ç³»åˆ—æˆ–å…¶ä»–æ›´æ–°çš„æ¨¡å‹ã€‚\n",
    "\n",
    "æœ‰[ä¸€äº›å¸¸è§å‚æ•°](https://docs.langchain.com/oss/python/langchain/models#parameters) å¯ä»¥ç”¨äºèŠå¤©æ¨¡å‹ã€‚å…¶ä¸­ä¸¤ä¸ªæœ€å¸¸ç”¨çš„æ˜¯ï¼š\n",
    "\n",
    "* `model`ï¼šæ¨¡å‹åç§°\n",
    "* `temperature`ï¼šé‡‡æ ·æ¸©åº¦\n",
    "\n",
    "`temperature` æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§æˆ–åˆ›é€ æ€§ï¼Œæ¸©åº¦ä½ï¼ˆæ¥è¿‘ 0ï¼‰æ—¶è¾“å‡ºæ›´ç¡®å®šã€æ›´èšç„¦ï¼Œé€‚ç”¨äºéœ€è¦å‡†ç¡®æˆ–åŸºäºäº‹å®çš„ä»»åŠ¡ï¼›æ¸©åº¦é«˜ï¼ˆæ¥è¿‘ 1ï¼‰æ—¶æ›´é€‚åˆåˆ›æ„ç±»ä»»åŠ¡æˆ–ç”Ÿæˆå¤šæ ·åŒ–å›å¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a54d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–æ¨¡å‹åç§°\n",
    "# OPENAI_API_KEY å’Œ OPENAI_API_BASE ä¹Ÿä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–\n",
    "model_name = os.environ.get(\"MODEL_NAME\")\n",
    "\n",
    "llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "\n",
    "rprint(f\"[cyan]å½“å‰ä½¿ç”¨æ¨¡å‹: {model_name}[/cyan]\")\n",
    "\n",
    "# æ³¨æ„ï¼šè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®æ¨¡å‹åç§°\n",
    "# ä¾‹å¦‚ï¼š\n",
    "# MODEL_NAME=deepseek-ai/DeepSeek-V3.2-Exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "LangChain ä¸­çš„èŠå¤©æ¨¡å‹æœ‰è®¸å¤š[é»˜è®¤æ–¹æ³•](https://reference.langchain.com/python/langchain_core/runnables)ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ï¼š\n",
    "\n",
    "* [stream](https://docs.langchain.com/oss/python/langchain/models#stream)ï¼šæµå¼è¿”å›å“åº”ç‰‡æ®µ\n",
    "* [invoke](https://docs.langchain.com/oss/python/langchain/models#invoke)ï¼šå¯¹è¾“å…¥è°ƒç”¨æ¨¡å‹\n",
    "\n",
    "å¦‚å‰æ‰€è¿°ï¼ŒèŠå¤©æ¨¡å‹ä»¥[æ¶ˆæ¯ï¼ˆmessagesï¼‰](https://docs.langchain.com/oss/python/langchain/messages)ä½œä¸ºè¾“å…¥ã€‚æ¶ˆæ¯æœ‰ä¸€ä¸ªè§’è‰²ï¼ˆæè¿°è°åœ¨è¯´è¯ï¼‰å’Œå†…å®¹å±æ€§ï¼ˆcontentï¼‰ã€‚æˆ‘ä»¬ä¹‹åä¼šæ›´è¯¦ç»†è®¨è®ºï¼Œè¿™é‡Œå…ˆå±•ç¤ºåŸºæœ¬ç”¨æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1280e1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello world! ğŸ‘‹ \\n\\nIt's great to see you! How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 8, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'deepseek-ai/DeepSeek-V3.2-Exp', 'system_fingerprint': '', 'id': '019a9c87aabab3722475eb9fd4fc8b77', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ccfb2fc3-9d63-4424-a159-8400f99abd8f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 20, 'total_tokens': 28, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª `AIMessage` å“åº”ã€‚å¦è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥ç”¨å­—ç¬¦ä¸²è°ƒç”¨èŠå¤©æ¨¡å‹ã€‚å½“ä»¥å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥æ—¶ï¼Œè¯¥å­—ç¬¦ä¸²ä¼šè¢«è½¬æ¢ä¸ºä¸€ä¸ª `HumanMessage`ï¼Œç„¶åä¼ é€’ç»™åº•å±‚æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CSWGCXlVYTEWoHAFm3GXIIgUO1gCb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--43b070a6-7676-4aa1-984c-c0cd43d45c1e-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CSWGDY5KePqihRcWDX3IGEZfSoyld', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f7963c03-f8b2-4eba-bc7f-4d58520fa661-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "ä¸åŒèŠå¤©æ¨¡å‹ä¹‹é—´çš„æ¥å£æ˜¯ä¸€è‡´çš„ï¼Œæ¨¡å‹é€šå¸¸åœ¨æ¯ä¸ªç¬”è®°æœ¬å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œå¦‚æœä½ æ›´åå¥½å…¶ä»–æä¾›å•†ï¼Œå¯ä»¥åœ¨ä¸æ›´æ”¹ä¸‹æ¸¸ä»£ç çš„æƒ…å†µä¸‹è½»æ¾åˆ‡æ¢æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## æœç´¢å·¥å…·\n",
    "\n",
    "åœ¨ README ä¸­ä½ è¿˜ä¼šçœ‹åˆ° [Tavily](https://tavily.com/)ï¼Œå®ƒæ˜¯ä¸€ä¸ªä¸º LLM å’Œ RAG ä¼˜åŒ–çš„æœç´¢å¼•æ“ï¼Œæ—¨åœ¨æä¾›é«˜æ•ˆã€å¿«é€Ÿä¸”æŒä¹…çš„æœç´¢ç»“æœã€‚å¦‚å‰æ‰€è¿°ï¼Œæ³¨å†Œå¾ˆå®¹æ˜“ä¸”æä¾›äº†å®½æ¾çš„å…è´¹é¢åº¦ã€‚ç¬¬ 4 æ¨¡å—ä¸­çš„æŸäº›è¯¾ç¨‹å°†é»˜è®¤ä½¿ç”¨ Tavilyï¼Œä½†å½“ç„¶å¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥åœ¨ä»£ç ä¸­æ›¿æ¢ä¸ºå…¶ä»–æœç´¢å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch  # updated at 1.0\n",
    "\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "data = tavily_search.invoke({\"query\": \"What is LangGraph?\"})\n",
    "type(data)\n",
    "search_docs = data.get(\"results\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'content': 'LangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows.',\n",
       "  'score': 0.9999968,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "  'score': 0.9999697,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph',\n",
       "  'title': 'What is LangGraph ? - Hugging Face Agents Course',\n",
       "  'content': 'Agents Course documentation [22,903](https://github.com/huggingface/agents-course) [Introduction to LangGraph](https://huggingface.co/learn/agents-course/en/unit2/langgraph/introduction)[What is LangGraph?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph)[Building Blocks of LangGraph](https://huggingface.co/learn/agents-course/en/unit2/langgraph/building_blocks)[Building Your First LangGraph](https://huggingface.co/learn/agents-course/en/unit2/langgraph/first_graph)[Document Analysis Graph](https://huggingface.co/learn/agents-course/en/unit2/langgraph/document_analysis_agent)[Quick Quiz 1](https://huggingface.co/learn/agents-course/en/unit2/langgraph/quiz1)[Conclusion](https://huggingface.co/learn/agents-course/en/unit2/langgraph/conclusion) [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#what-is-langgraph-)What is LangGraph ? `LangGraph` is a framework developed by [LangChain](https://www.langchain.com/)**to manage the control flow of applications that integrate an LLM**. [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#is-langgraph-different-from-langchain-)Is LangGraph different from LangChain ? [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#when-should-i-use-langgraph-)When should I use LangGraph ? ### [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#control-vs-freedom)Control vs freedom ![Image 3: Control flow](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/LangGraph/flow.png) [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#how-does-langgraph-work)How does LangGraph work? [](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#how-is-it-different-from-regular-python-why-do-i-need-langgraph)How is it different from regular python? [<>Update on GitHub](https://github.com/huggingface/agents-course/blob/main/units/en/unit2/langgraph/when_to_use_langgraph.mdx) [â†Introduction to LangGraph](https://huggingface.co/learn/agents-course/en/unit2/langgraph/introduction)[Building Blocks of LangGraphâ†’](https://huggingface.co/learn/agents-course/en/unit2/langgraph/building_blocks) [What is Lang Graph ?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#what-is-langgraph-)[Is Lang Graph different from Lang Chain ?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#is-langgraph-different-from-langchain-)[When should I use Lang Graph ?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#when-should-i-use-langgraph-)[Control vs freedom](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#control-vs-freedom)[How does Lang Graph work?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#how-does-langgraph-work)[How is it different from regular python? Why do I need Lang Graph?](https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph#how-is-it-different-from-regular-python-why-do-i-need-langgraph)',\n",
       "  'score': 0.9997131,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7545f4-aeb7-4b03-91f5-df3e021fe960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
